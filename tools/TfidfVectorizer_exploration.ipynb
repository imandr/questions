{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from collections import Counter\n",
    "import math, random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MaxQuestionLength = 40   # words\n",
    "MaxMissingWords = 2*MaxQuestionLength\n",
    "\n",
    "def normalize_question(q):\n",
    "    q = q.lower()\n",
    "    q = q.replace(\"?\",\" ? \")\n",
    "    q = q.replace(\"...\",\" . \")\n",
    "    q = q.replace(\"..\",\" . \")\n",
    "    q = q.replace(\".\",\" . \")\n",
    "    q = q.replace(\":\",\" : \")\n",
    "    q = q.replace(\",\",\" , \")\n",
    "    q = q.replace(\"[math]\", \" [math] \")\n",
    "    q = q.replace(\"/\",\" / \")\n",
    "    q = q.replace(\"[ / math]\", \" [/math] \")\n",
    "    q = q.replace(\"{\",\" { \")\n",
    "    q = q.replace(\"}\",\" } \")\n",
    "    q = q.replace(\"(\",\" ( \")\n",
    "    q = q.replace(\")\",\" ) \")\n",
    "    q = q.replace(\"^\",\" ^ \")\n",
    "    q = q.replace(\"n't\",\" not \")    \n",
    "    q = q.replace(\"i'm\", \"i am\")\n",
    "    q = q.replace(\"-\",\" - \")\n",
    "    q = q.replace('\"',' \" ')\n",
    "    q = q.replace('\\xe2\\x80\\x9c', ' \" ').replace('\\xe2\\x80\\x9d', ' \" ')    \n",
    "    q = q.replace(\"'s\", \" 's \")\n",
    "    words = q.lower().split()[:MaxQuestionLength]\n",
    "    #words = map(lambda x: x.strip(), words)\n",
    "    #words = filter(lambda x: len(x) > 0, words)\n",
    "    #words = map(lambda w: w[:-1] + \" s\" if len(w)>3 and w[-1]=='s' and \n",
    "    #            not w in (\"this\", \"does\") else w, words)\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_pair(q1, q2):\n",
    "    # q1 and q2 are unnormalized questions\n",
    "    \n",
    "    q1 = normalize_question(q1)\n",
    "    q2 = normalize_question(q2)\n",
    "    q1_words = q1.split()\n",
    "    q2_words = q2.split()\n",
    "    q1_words_set = set(q1_words)\n",
    "    q2_words_set = set(q2_words)\n",
    "    union = q1_words_set | q2_words_set\n",
    "    encoding = { w: \"<%d>\" % (i,) for i, w in enumerate(union) }\n",
    "    q1_encoded = \" \".join([encoding[w] for w in q1_words])\n",
    "    q2_encoded = \" \".join([encoding[w] for w in q2_words])\n",
    "    return q1_encoded, q2_encoded\n",
    "\n",
    "def tfidSimilarity(tuples):\n",
    "    # tuples are expected to be (q1, q2)\n",
    "    qset = set((q1 for q1, q2 in tuples)) | set((q2 for q1, q2 in tuples))\n",
    "    qlist = list(qset)\n",
    "    qdict = { q:i for i, q in enumerate(qlist) }\n",
    "\n",
    "    vectorizer = TfidfVectorizer(min_df=2, stop_words = 'english',\\\n",
    "        strip_accents = 'unicode', lowercase=True, ngram_range=(1,2),\\\n",
    "        norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n",
    "\n",
    "    X = vectorizer.fit_transform(qlist)\n",
    "    return np.array(\n",
    "        \n",
    "    )\n",
    "        \n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'find the remainder when [math] 23 ^ { 24 } [/math] is divided by 24 , 23 ?'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_question(\"Find the remainder when [math]23^{24}[/math] is divided by 24,23?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=2, stop_words = 'english',\\\n",
    "strip_accents = 'unicode', lowercase=True, ngram_range=(1,2),\\\n",
    "norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set loaded: 404290\n"
     ]
    }
   ],
   "source": [
    "train_df=pd.read_csv(\"/Users/ivm/ivm/Projects/Neural/kaggle/questions/data/train.csv\")\n",
    "train_df.fillna(\"\", inplace=True)\n",
    "print \"Train set loaded:\", len(train_df)\n",
    "\n",
    "questions_indexed = { qid:normalize_question(q) for _, qid, q in train_df[[\"qid1\",\"question1\"]].itertuples() }\n",
    "questions_indexed.update( { qid:normalize_question(q) for _, qid, q in train_df[[\"qid2\",\"question2\"]].itertuples() } )\n",
    "\n",
    "questions_normalized = sorted(questions_indexed.items())\n",
    "\n",
    "questions_normalized_df = pd.DataFrame([q for i, q in questions_normalized], columns=[\"question\"], \n",
    "                                       index=[i for i, q in questions_normalized])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " total train words: 96140\n"
     ]
    }
   ],
   "source": [
    "train_questions = questions_normalized_df[\"question\"]\n",
    "\n",
    "def word_frequencies(questions):\n",
    "    words = \" \".join(questions).split(\" \")\n",
    "    counter = Counter(words)\n",
    "    return sorted(counter.items(), key=lambda x:-x[1])\n",
    "\n",
    "train_words_frequencies = word_frequencies(train_questions)\n",
    "print \"total train words:\", len(train_words_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NMostFrequent = 10000\n",
    "most_frequent_words = [w for w, n in train_words_frequencies[:NMostFrequent]]\n",
    "most_frequent_words_set = set(most_frequent_words)\n",
    "\n",
    "InfrequentWords = [\"<%d>\" % (NMostFrequent+k+1,) for k in range(MaxMissingWords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_question_from_pair(q_words, frequent_set, infrequent_encoding):\n",
    "    return [w if w in frequent_set else infrequent_encoding[w] for w in q_words]\n",
    "    \n",
    "\n",
    "def reduce_pair(q1, q2, frequent_set, infrequent_vocabulary):\n",
    "    # q1 and q2 are unnormalized questions\n",
    "    \n",
    "    q1 = normalize_question(q1)\n",
    "    q2 = normalize_question(q2)\n",
    "    q1_words = q1.split()\n",
    "    q2_words = q2.split()\n",
    "    q1_words_set = set(q1_words)\n",
    "    q2_words_set = set(q2_words)\n",
    "    union = q1_words_set | q2_words_set\n",
    "    #print \"union:\", union\n",
    "    infrequent = union - frequent_set\n",
    "    #print \"infrequent:\", infrequent\n",
    "    unknown_vocabulary = random.sample(infrequent_vocabulary, len(infrequent))\n",
    "    unknown_encoding = {w: unknown_vocabulary[i] for i, w in enumerate(infrequent)}\n",
    "    \n",
    "    q1_encoded = reduce_question_from_pair(q1_words, frequent_set, unknown_encoding)\n",
    "    q2_encoded = reduce_question_from_pair(q2_words, frequent_set, unknown_encoding)\n",
    "    return \" \".join(q1_encoded), \" \".join(q2_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_pairs_df = pd.DataFrame([\n",
    "    reduce_pair(q1, q2, most_frequent_words_set, InfrequentWords)+(qid1, qid2, is_dup)\n",
    "        for _, q1, q2, qid1, qid2, is_dup in train_df[[\"question1\",\"question2\",\"qid1\",\"qid2\",\"is_duplicate\"]].itertuples()\n",
    "], columns=[\"question1\", \"question2\",\"qid1\",\"qid2\",\"is_duplicate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the story of &lt;10015&gt; ( &lt;10053&gt; - i - &lt;...</td>\n",
       "      <td>what would happen if the indian government &lt;10...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>why am i mentally very lonely ? how can i solv...</td>\n",
       "      <td>find the remainder when [math] &lt;10005&gt; / math]...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>which one dissolve in water &lt;10064&gt; sugar , sa...</td>\n",
       "      <td>which fish would survive in salt water ?</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>astrology : i am a capricorn sun cap moon and ...</td>\n",
       "      <td>i am a triple capricorn ( sun , moon and ascen...</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>should i buy &lt;10033&gt; ?</td>\n",
       "      <td>what keeps &lt;10061&gt; active and far from phone a...</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>how can i be a good &lt;10027&gt; ?</td>\n",
       "      <td>what should i do to be a great &lt;10027&gt; ?</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>when do you use &lt;10035&gt; instead of &lt;10059&gt; ?</td>\n",
       "      <td>when do you use \" &amp; \" instead of \" and \" ?</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>motorola ( company ) : can i hack my charter &lt;...</td>\n",
       "      <td>how do i hack motorola &lt;10025&gt; for free intern...</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  what is the step by step guide to invest in sh...   \n",
       "1  what is the story of <10015> ( <10053> - i - <...   \n",
       "2  how can i increase the speed of my internet co...   \n",
       "3  why am i mentally very lonely ? how can i solv...   \n",
       "4  which one dissolve in water <10064> sugar , sa...   \n",
       "5  astrology : i am a capricorn sun cap moon and ...   \n",
       "6                             should i buy <10033> ?   \n",
       "7                      how can i be a good <10027> ?   \n",
       "8       when do you use <10035> instead of <10059> ?   \n",
       "9  motorola ( company ) : can i hack my charter <...   \n",
       "\n",
       "                                           question2  qid1  qid2  is_duplicate  \n",
       "0  what is the step by step guide to invest in sh...     1     2             0  \n",
       "1  what would happen if the indian government <10...     3     4             0  \n",
       "2  how can internet speed be increased by hacking...     5     6             0  \n",
       "3  find the remainder when [math] <10005> / math]...     7     8             0  \n",
       "4           which fish would survive in salt water ?     9    10             0  \n",
       "5  i am a triple capricorn ( sun , moon and ascen...    11    12             1  \n",
       "6  what keeps <10061> active and far from phone a...    13    14             0  \n",
       "7           what should i do to be a great <10027> ?    15    16             1  \n",
       "8         when do you use \" & \" instead of \" and \" ?    17    18             0  \n",
       "9  how do i hack motorola <10025> for free intern...    19    20             0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_pairs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reduced_questions_indexed = { qid:q for _, qid, q in reduced_pairs_df[[\"qid1\",\"question1\"]].itertuples() }\n",
    "reduced_questions_indexed.update( { qid:q for _, qid, q in reduced_pairs_df[[\"qid2\",\"question2\"]].itertuples() } )\n",
    "\n",
    "reduced_questions_normalized = sorted(reduced_questions_indexed.items())\n",
    "\n",
    "reduced_questions_normalized_df = pd.DataFrame([q for i, q in reduced_questions_normalized], columns=[\"question\"], \n",
    "                                       index=[i for i, q in reduced_questions_normalized])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_reduced = vectorizer.fit_transform(reduced_questions_normalized_df[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_distances_and_dups = [\n",
    "    (X_reduced[qid1-1].toarray().dot(X_reduced[qid2-1].toarray().T)[0][0], is_dup)\n",
    "    for _, qid1, qid2, is_dup in train_df[[\"qid1\",\"qid2\",\"is_duplicate\"]].itertuples()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.299349403229\n"
     ]
    }
   ],
   "source": [
    "reduced_distances_and_dups = np.array(reduced_distances_and_dups)\n",
    "reduced_loss = -np.mean(np.log(reduced_distances_and_dups[:,0]+0.00001)*reduced_distances_and_dups[:,1])\n",
    "print loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(questions_normalized_df[\"question\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].toarray().dot(X[4].toarray().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'id', u'qid1', u'qid2', u'question1', u'question2', u'is_duplicate'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distances_and_dups = [\n",
    "    (X[qid1-1].toarray().dot(X[qid2-1].toarray().T)[0][0], is_dup)\n",
    "    for _, qid1, qid2, is_dup in train_df[[\"qid1\",\"qid2\",\"is_duplicate\"]].itertuples()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>is_dup</th>\n",
       "      <th>rounded_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.941080</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.814216</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.121902</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.119912</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.579761</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.824822</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.659802</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.928690</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.791980</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.891310</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.190392</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.867107</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.196804</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.495863</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    distance  is_dup  rounded_distance\n",
       "0   0.941080       0               1.0\n",
       "1   0.814216       0               1.0\n",
       "2   0.121902       0               0.0\n",
       "3   0.000000       0               0.0\n",
       "4   0.119912       0               0.0\n",
       "5   0.579761       1               1.0\n",
       "6   0.000000       0               0.0\n",
       "7   0.824822       1               1.0\n",
       "8   1.000000       0               1.0\n",
       "9   0.659802       0               1.0\n",
       "10  0.000000       0               0.0\n",
       "11  0.928690       1               1.0\n",
       "12  1.000000       1               1.0\n",
       "13  0.791980       1               1.0\n",
       "14  0.891310       0               1.0\n",
       "15  0.190392       1               0.0\n",
       "16  0.867107       1               1.0\n",
       "17  0.000000       0               0.0\n",
       "18  0.196804       1               0.0\n",
       "19  0.495863       0               0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances_df = pd.DataFrame(distances_and_dups, columns=[\"distance\", \"is_dup\"])\n",
    "distances_df[\"rounded_distance\"] = map(round, distances_df[\"distance\"])\n",
    "distances_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.299349403229\n"
     ]
    }
   ],
   "source": [
    "loss = -np.mean(np.log(distances_df[\"distance\"]+0.00001)*distances_df[\"is_dup\"])\n",
    "print loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
